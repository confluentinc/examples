global:
  # How frequently to scrape targets by default.
  # Default 15s
  scrape_interval: 60s
  # How frequently to evaluate rules.
  # Default 15s
  evaluation_interval: 15s
  # How long until a scrape request times out.
  # Default to 10s.
  # Required because cp-demo is using cpu throttling, so let's leave enough time to fetch the metrics in particular for the first time as it needs to compile all rexps
  scrape_timeout: 30s

rule_files:
  - "alert.rules"

alerting:
  alertmanagers:
    - scheme: http
      static_configs:
        - targets:
            - "alertmanager:9093"

scrape_configs:
  - job_name: "prometheus"
    static_configs:
      - targets: ["localhost:9090"]

  - job_name: "node-exporter"
    static_configs:
      - targets: ["node-exporter:9100"]

  - job_name: "producer"
    static_configs:
      - targets: ["producer:1234"]
        labels:
          env: "dev"

  - job_name: "consumer"
    static_configs:
      - targets: ["consumer:1234"]
        labels:
          env: 'dev'

  - job_name: confluent-cloud
    static_configs:
      - targets:
        - api.telemetry.confluent.cloud
        labels:
          env: "dev"
    scheme: https
    basic_auth:
      username: ""
      password: ""
    metrics_path: /v2/metrics/cloud/export
    params:
      "resource.kafka.id": []
      "resource.connector.id": []
      "resource.ksql.id": []
      "resource.schema_registry.id": []

  - job_name: "kafka-lag-exporter"
    static_configs:
      - targets:
          - "kafka-lag-exporter:9999"
        labels:
          env: "dev"
