---
version: '2.3'
services:
  zookeeper:
    image: ${PREFIX}/cp-zookeeper:${TAG}
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    healthcheck:
      test: nc -z localhost 2181
      interval: 5s
      retries: 5
      start_period: 30s
  # https://github.com/rroemhild/docker-test-openldap
  # but user amy doesn't work for some reason, seems like invalid password but maybe smth else
  openldap:
    image: rroemhild/test-openldap
    hostname: openldap
    container_name: openldap
    ports:
      - "389:389"
    privileged: true

  broker:
    image: ${PREFIX}/cp-server:${TAG}
    hostname: broker
    container_name: broker
    depends_on:
      zookeeper:
        condition: service_healthy
      openldap:
        condition: service_started
    ports:
      - "8090:8090"
      - "9092:9092"
      - "9093:9093"
      - "9094:9094"
    volumes:
      - ./conf:/tmp/conf
      - ./client-configs:/etc/client-configs
      - ./kafka-registered.sh:/etc/kafka-registered.sh
    healthcheck:
      test: nc -z localhost 8090 && nc -z localhost 9094 && /etc/kafka-registered.sh zookeeper:2181
      interval: 3s
      retries: 15
      start_period: 30s
    environment:
      # ============= CONFIG SHARED BY BROKER AND MDS ===============
      # Setup super.users with unlimited access to cluster
      # for broker it means unlimited access to broker
      # for MDS it means unlimited access to MDS
      # admin is for broker-to-broker communication
      # mds is for MDS to talk to broker
      # professor is an LDAP user - for initial bootstrapping of MDS users
      KAFKA_SUPER_USERS: User:admin;User:mds;User:professor
      
      # ===================== CONFIGURE BROKER =======================
      # GENERAL CONFIG
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      
      # CONFIGURE LISTENERS
      # RBAC needs separate internal and external listeners
      # OUTSIDE listener is needed if you want to talk to this kafka from your macbook - your macbook is not member of docker network
      # created by compose, so won't know the hostname called 'broker', which will be returned in a list of listeners when console producer or consumer
      # try to get full listener list from bootstrap server
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://localhost:9093,EXTERNAL://broker:9092,OUTSIDE://localhost:9094
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:SASL_PLAINTEXT,EXTERNAL:SASL_PLAINTEXT,OUTSIDE:SASL_PLAINTEXT
      KAFKA_CONFLUENT_METADATA_SECURITY_PROTOCOL: SASL_PLAINTEXT
      
      # Configure interbroker listener
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_SASL_MECHANISM_INTER_BROKER_PROTOCOL: PLAIN
      KAFKA_LISTENER_NAME_INTERNAL_SASL_ENABLED_MECHANISMS: PLAIN
      # note we're only specifying two users, one for broker-to-broker communication (admin) and one for MDS to talk to broker (mds)
      KAFKA_LISTENER_NAME_INTERNAL_PLAIN_SASL_JAAS_CONFIG: |
                                                            \
                                                            org.apache.kafka.common.security.plain.PlainLoginModule required \
                                                            username="admin" \
                                                            password="admin-secret" \
                                                            user_admin="admin-secret" \
                                                            user_mds="mds-secret";

      # Configure external listener
      KAFKA_LISTENER_NAME_EXTERNAL_SASL_ENABLED_MECHANISMS: OAUTHBEARER
      KAFKA_LISTENER_NAME_EXTERNAL_OAUTHBEARER_SASL_SERVER_CALLBACK_HANDLER_CLASS: io.confluent.kafka.server.plugins.auth.token.TokenBearerValidatorCallbackHandler
      KAFKA_LISTENER_NAME_EXTERNAL_OAUTHBEARER_SASL_LOGIN_CALLBACK_HANDLER_CLASS: io.confluent.kafka.server.plugins.auth.token.TokenBearerServerLoginCallbackHandler
      KAFKA_LISTENER_NAME_EXTERNAL_OAUTHBEARER_SASL_JAAS_CONFIG: |
                                                                 \
                                                                 org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required \
                                                                 publicKeyPath="/tmp/conf/public.pem";

      # Configure external listener
      KAFKA_LISTENER_NAME_OUTSIDE_SASL_ENABLED_MECHANISMS: OAUTHBEARER
      KAFKA_LISTENER_NAME_OUTSIDE_OAUTHBEARER_SASL_SERVER_CALLBACK_HANDLER_CLASS: io.confluent.kafka.server.plugins.auth.token.TokenBearerValidatorCallbackHandler
      KAFKA_LISTENER_NAME_OUTSIDE_OAUTHBEARER_SASL_LOGIN_CALLBACK_HANDLER_CLASS: io.confluent.kafka.server.plugins.auth.token.TokenBearerServerLoginCallbackHandler
      KAFKA_LISTENER_NAME_OUTSIDE_OAUTHBEARER_SASL_JAAS_CONFIG: |
                                                                 \
                                                                 org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required \
                                                                 publicKeyPath="/tmp/conf/public.pem";
      
      # CONFIGURE AUTHORIZER
      # Setup kafka to use RBAC authorizer
      KAFKA_AUTHORIZER_CLASS_NAME: io.confluent.kafka.security.authorizer.ConfluentServerAuthorizer

      # ======================== CONFIGURE MDS ====================================
      # Configure how MDS talks to broker
      KAFKA_CONFLUENT_METADATA_BOOTSTRAP_SERVERS: INTERNAL://localhost:9093
      KAFKA_CONFLUENT_METADATA_SASL_MECHANISM: PLAIN
      KAFKA_CONFLUENT_METADATA_SASL_JAAS_CONFIG: |
                                                  \
                                                  org.apache.kafka.common.security.plain.PlainLoginModule required \
                                                  username="mds" \
                                                  password="mds-secret";
      # Configure how MDS stores its data in a topic
      # supposedly more stuff can be overridden with the same prefix
      KAFKA_CONFLUENT_METADATA_TOPIC_REPLICATION_FACTOR: 1

      # Configure MDS listener and http server
      KAFKA_CONFLUENT_METADATA_SERVER_AUTHENTICATION_METHOD: BASIC
      KAFKA_CONFLUENT_METADATA_SERVER_AUTHENTICATION_ROLES: '**'
      KAFKA_CONFLUENT_METADATA_SERVER_LISTENERS: http://0.0.0.0:8090
      KAFKA_CONFLUENT_METADATA_SERVER_ADVERTISED_LISTENERS: http://broker:8090

      # Configure RBAC token server (authentication)
      KAFKA_CONFLUENT_METADATA_SERVER_TOKEN_AUTH_ENABLE: 'true'
      KAFKA_CONFLUENT_METADATA_SERVER_TOKEN_MAX_LIFETIME_MS: 3600000
      KAFKA_CONFLUENT_METADATA_SERVER_TOKEN_SIGNATURE_ALGORITHM: RS256
      KAFKA_CONFLUENT_METADATA_SERVER_TOKEN_KEY_PATH: /tmp/conf/keypair.pem
      KAFKA_CONFLUENT_METADATA_SERVER_PUBLIC_KEY_PATH: /tmp/conf/public.pem

      # Configure RBAC authorizer
      # KAFKA_CONFLUENT_AUTHORIZER_SCOPE: myCluster
      KAFKA_CONFLUENT_AUTHORIZER_ACCESS_RULE_PROVIDERS: RBAC
      # KAFKA_CONFLUENT_AUTHORIZER_METADATA_PROVIDER: RBAC
      KAFKA_CONFLUENT_AUTHORIZER_GROUP_PROVIDER: RBAC
      # KAFKA_CONFLUENT_METADATA_SERVER_SCOPE: ''

      # Configure MDS to talk to AD/LDAP
      KAFKA_LDAP_JAVA_NAMING_FACTORY_INITIAL: com.sun.jndi.ldap.LdapCtxFactory
      KAFKA_LDAP_COM_SUN_JNDI_LDAP_READ_TIMEOUT: 3000
      KAFKA_LDAP_JAVA_NAMING_PROVIDER_URL: ldap://openldap:389
      # how to authenticate to LDAP
      KAFKA_LDAP_JAVA_NAMING_SECURITY_PRINCIPAL: cn=admin,dc=planetexpress,dc=com
      KAFKA_LDAP_JAVA_NAMING_SECURITY_CREDENTIALS: GoodNewsEveryone
      KAFKA_LDAP_JAVA_NAMING_SECURITY_AUTHENTICATION: simple
      # how to locate users and groups
      KAFKA_LDAP_USER_SEARCH_BASE: ou=people,dc=planetexpress,dc=com
      KAFKA_LDAP_GROUP_SEARCH_BASE: ou=people,dc=planetexpress,dc=com
      KAFKA_LDAP_USER_NAME_ATTRIBUTE: uid
      KAFKA_LDAP_USER_OBJECT_CLASS: inetOrgPerson
      KAFKA_LDAP_USER_MEMBEROF_ATTRIBUTE: ou
      KAFKA_LDAP_GROUP_NAME_ATTRIBUTE: cn
      KAFKA_LDAP_GROUP_OBJECT_CLASS: group

      # ======================= CONFIGURE METRICS REPORTER =========================
      KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
      CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 1

      # point at our 'INTERNAL' listener
      CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: broker:9093
      # CONFLUENT_METRICS_REPORTER_ZOOKEEPER_CONNECT: zookeeper:2181
      CONFLUENT_METRICS_REPORTER_SECURITY_PROTOCOL: SASL_PLAINTEXT
      CONFLUENT_METRICS_REPORTER_SASL_MECHANISM: PLAIN
      CONFLUENT_METRICS_REPORTER_SASL_JAAS_CONFIG: |
                                                    \
                                                    org.apache.kafka.common.security.plain.PlainLoginModule required \
                                                    username="admin" \
                                                    password="admin-secret";

      # ======================= OTHER BROKER STUFF =================================
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      # KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      # CONFLUENT_METRICS_ENABLE: 'true'
      # CONFLUENT_SUPPORT_CUSTOMER_ID: 'anonymous'

  schema-registry:
    image: ${PREFIX}/cp-schema-registry:${TAG}
    hostname: schema-registry
    container_name: schema-registry
    depends_on:
      broker:
        condition: service_healthy
    ports:
      - "8081:8081"
    volumes:
      - ./conf:/tmp/conf
    healthcheck:
        test: nc -z localhost 8081
        interval: 3s
        retries: 15
        start_period: 30s
    environment:
      CUB_CLASSPATH: '/etc/confluent/docker/docker-utils.jar:/usr/share/java/confluent-security/schema-registry/*:/usr/share/java/schema-registry/*'
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      # This is only needed if you don't have a license and would like to test as part of a trial period
      SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL: zookeeper:2181
      
      # configure how to connect to kafka for SR to store its internal info
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: broker:9092
      SCHEMA_REGISTRY_KAFKASTORE_SECURITY_PROTOCOL: SASL_PLAINTEXT
      SCHEMA_REGISTRY_KAFKASTORE_SASL_MECHANISM: OAUTHBEARER
      SCHEMA_REGISTRY_KAFKASTORE_SASL_LOGIN_CALLBACK_HANDLER_CLASS: io.confluent.kafka.clients.plugins.auth.token.TokenUserLoginCallbackHandler
      SCHEMA_REGISTRY_KAFKASTORE_SASL_JAAS_CONFIG: |
                                                    \
                                                    org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required \
                                                    username="leela" \
                                                    password="leela" \
                                                    metadataServerUrls="http://broker:8090";
      SCHEMA_REGISTRY_KAFKASTORE_TOPIC: _schemas
      SCHEMA_REGISTRY_DEBUG: 'true'

      # ======================= RBAC =================================
      SCHEMA_REGISTRY_SCHEMA_REGISTRY_RESOURCE_EXTENSION_CLASS: io.confluent.kafka.schemaregistry.security.SchemaRegistrySecurityResourceExtension
      SCHEMA_REGISTRY_CONFLUENT_SCHEMA_REGISTRY_AUTHORIZER_CLASS: io.confluent.kafka.schemaregistry.security.authorizer.rbac.RbacAuthorizer
      SCHEMA_REGISTRY_REST_SERVLET_INITIALIZOR_CLASSES: io.confluent.common.security.jetty.initializer.InstallBearerOrBasicSecurityHandler
      # how to connect to MDS
      SCHEMA_REGISTRY_CONFLUENT_METADATA_BOOTSTRAP_SERVER_URLS: http://broker:8090
      SCHEMA_REGISTRY_CONFLUENT_METADATA_HTTP_AUTH_CREDENTIALS_PROVIDER: BASIC
      SCHEMA_REGISTRY_CONFLUENT_METADATA_BASIC_AUTH_USER_INFO: leela:leela
      # public key to verify tokens during authentication
      SCHEMA_REGISTRY_PUBLIC_KEY_PATH: /tmp/conf/public.pem
  
  ksql-server:
    image: ${PREFIX}/cp-ksql-server:${TAG}
    hostname: ksql-server
    container_name: ksql-server
    depends_on:
      broker:
        condition: service_healthy
      schema-registry:
        condition: service_healthy
    ports:
      - "8088:8088"
    volumes:
      - ./conf:/tmp/conf
    healthcheck:
        test: nc -z localhost 8088
        interval: 3s
        retries: 15
        start_period: 30s
    environment:
      CUB_CLASSPATH: '/usr/share/java/ksql-server/*:/usr/share/java/cp-base-new/*'
      KSQL_LOG4J_ROOT_LOGLEVEL: TRACE
      KSQL_BOOTSTRAP_SERVERS: "broker:9092"
      KSQL_HOST_NAME: ksql-server
      KSQL_APPLICATION_ID: "rbac-compose-demo"
      KSQL_LISTENERS: "http://0.0.0.0:8088"
      KSQL_CACHE_MAX_BYTES_BUFFERING: 0
      # KSQL cluster id
      KSQL_KSQL_SERVICE_ID: ksql-cluster

      # enable rbac confluent security plugin
      KSQL_KSQL_SECURITY_EXTENSION_CLASS: io.confluent.ksql.security.KsqlConfluentSecurityExtension

      # Enable KSQL OAuth authentication
      KSQL_REST_SERVLET_INITIALIZOR_CLASSES: io.confluent.common.security.jetty.initializer.InstallBearerOrBasicSecurityHandler
      KSQL_WEBSOCKET_SERVLET_INITIALIZOR_CLASSES: io.confluent.common.security.jetty.initializer.InstallOAuthSecurityHandler
      KSQL_OAUTH_JWT_PUBLIC_KEY_PATH: /tmp/conf/public.pem
      KSQL_CONFLUENT_METADATA_PUBLIC_KEY_PATH: /tmp/conf/public.pem
      KSQL_PUBLIC_KEY_PATH: /tmp/conf/public.pem

      # How to connect to MDS
      KSQL_CONFLUENT_METADATA_BOOTSTRAP_SERVER_URLS: http://broker:8090
      KSQL_CONFLUENT_METADATA_HTTP_AUTH_CREDENTIALS_PROVIDER: BASIC
      KSQL_CONFLUENT_METADATA_BASIC_AUTH_CREDENTIALS_PROVIDER: USER_INFO
      KSQL_CONFLUENT_METADATA_BASIC_AUTH_USER_INFO: zoidberg:zoidberg

      # Credentials for kafka access
      KSQL_SECURITY_PROTOCOL: SASL_PLAINTEXT
      KSQL_SASL_MECHANISM: OAUTHBEARER
      KSQL_SASL_JAAS_CONFIG: |
                              \
                              org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required \
                              username="zoidberg" \
                              password="zoidberg" \
                              metadataServerUrls="http://broker:8090";
      KSQL_SASL_LOGIN_CALLBACK_HANDLER_CLASS: io.confluent.kafka.clients.plugins.auth.token.TokenUserLoginCallbackHandler

      KSQL_KSQL_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
      KSQL_KSQL_SCHEMA_REGISTRY_BASIC_AUTH_CREDENTIALS_SOURCE: USER_INFO
      KSQL_KSQL_SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO: zoidberg:zoidberg
      # KSQL_PRODUCER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor"
      # KSQL_CONSUMER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor"

  rest-proxy:
    image: ${PREFIX}/cp-kafka-rest:${TAG}
    hostname: rest-proxy
    container_name: rest-proxy
    depends_on:
      broker:
        condition: service_healthy
      schema-registry:
        condition: service_healthy
    ports:
      - 8082:8082
    volumes:
      - ./conf:/tmp/conf
    healthcheck:
        test: nc -z localhost 8082
        interval: 3s
        retries: 15
        start_period: 30s
    environment:
      KAFKA_REST_HOST_NAME: rest-proxy
      KAFKA_REST_ID: kafka-rest-test-server
      KAFKA_REST_DEBUG: 'true'
      KAFKA_REST_LISTENERS: http://0.0.0.0:8082
      # zookeeper connnect is for validating trial license
      KAFKA_REST_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_REST_BOOTSTRAP_SERVERS: broker:9092
      # =================== Credentials and classpath for cub kafka-ready ====================
      CUB_CLASSPATH: '/etc/confluent/docker/docker-utils.jar:/usr/share/java/confluent-security/kafka-rest/*:/usr/share/java/kafka-rest/*'
      KAFKA_REST_CLIENT_SECURITY_PROTOCOL: SASL_PLAINTEXT
      KAFKA_REST_CLIENT_SASL_MECHANISM: OAUTHBEARER
      KAFKA_REST_CLIENT_SASL_LOGIN_CALLBACK_HANDLER_CLASS: io.confluent.kafka.clients.plugins.auth.token.TokenUserLoginCallbackHandler
      KAFKA_REST_CLIENT_SASL_JAAS_CONFIG: |
                                          \
                                          org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required \
                                          username="fry" \
                                          password="fry" \
                                          metadataServerUrls="http://broker:8090";
      # =================== RBAC ==============================
      KAFKA_REST_KAFKA_REST_RESOURCE_EXTENSION_CLASS: io.confluent.kafkarest.security.KafkaRestSecurityResourceExtension
      KAFKA_REST_REST_SERVLET_INITIALIZOR_CLASSES: io.confluent.common.security.jetty.initializer.InstallBearerOrBasicSecurityHandler
      KAFKA_REST_PUBLIC_KEY_PATH: /tmp/conf/public.pem
      KAFKA_REST_CONFLUENT_METADATA_SERVER_URLS_MAX_AGE_MS: 60000
      KAFKA_REST_CLIENT_CONFLUENT_METADATA_SERVER_URLS_MAX_AGE_MS: 60000
      # how to connect to MDS
      KAFKA_REST_CONFLUENT_METADATA_BOOTSTRAP_SERVER_URLS: http://broker:8090
      KAFKA_REST_CONFLUENT_METADATA_HTTP_AUTH_CREDENTIALS_PROVIDER: BASIC
      KAFKA_REST_CONFLUENT_METADATA_BASIC_AUTH_USER_INFO: 'fry:fry'

      KAFKA_REST_SCHEMA_REGISTRY_URL: 'http://schema-registry:8081'

  connect:
    image: ${PREFIX}/cp-server-connect:${TAG}
    hostname: connect
    container_name: connect
    depends_on:
      broker:
        condition: service_healthy
      schema-registry:
        condition: service_healthy
    ports:
      - "8083:8083"
    volumes:
      - ./conf:/tmp/conf
      - ./connect-source:/tmp/connect-source
      - ./connect-sink:/tmp/connect-sink
    healthcheck:
        test: nc -z localhost 8083
        interval: 3s
        retries: 15
        start_period: 30s
    environment:
      CUB_CLASSPATH: '/etc/confluent/docker/docker-utils.jar:/usr/share/java/confluent-security/connect/*:/usr/share/java/kafka/*'
      # we can run without zookeeper connect in local environment
      # CONNECT_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      
      # general settings
      CONNECT_REST_ADVERTISED_HOST_NAME: connect
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: connect-cluster
      # configs storage topic
      CONNECT_CONFIG_STORAGE_TOPIC: connect-configs
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      # offsets storage topic and settings
      CONNECT_OFFSET_STORAGE_TOPIC: connect-offsets
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_FLUSH_INTERVAL_MS: 10000
      # status storage topic
      CONNECT_STATUS_STORAGE_TOPIC: connect-status
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      
      # Key and value converters
      # Example of String converter:
      # CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      
      # Example of Avro converter:
      # CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      # CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      # CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE: 'true'
      # CONNECT_VALUE_CONVERTER_BASIC_AUTH_USER_INFO: bender:bender
      # CONNECT_VALUE_CONVERTER_BASIC_AUTH_CREDENTIALS_SOURCE: USER_INFO
      
      # Default to Json converters:
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_INTERNAL_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_INTERNAL_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter

      # Connect to broker
      CONNECT_BOOTSTRAP_SERVERS: 'broker:9092'
      CONNECT_SECURITY_PROTOCOL: 'SASL_PLAINTEXT'
      CONNECT_SASL_MECHANISM: 'OAUTHBEARER'
      CONNECT_SASL_LOGIN_CALLBACK_HANDLER_CLASS: 'io.confluent.kafka.clients.plugins.auth.token.TokenUserLoginCallbackHandler'
      CONNECT_SASL_JAAS_CONFIG: |
                                \
                                org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required \
                                username="fry" \
                                password="fry" \
                                metadataServerUrls="http://broker:8090";

      # Allow overriding configs on the connector level
      CONNECT_CONNECTOR_CLIENT_CONFIG_OVERRIDE_POLICY: 'All'
      # Default producer configs
      CONNECT_PRODUCER_SECURITY_PROTOCOL: 'SASL_PLAINTEXT'
      CONNECT_PRODUCER_SASL_MECHANISM: 'OAUTHBEARER'
      CONNECT_PRODUCER_SASL_LOGIN_CALLBACK_HANDLER_CLASS: 'io.confluent.kafka.clients.plugins.auth.token.TokenUserLoginCallbackHandler'
      # Default consumer configs
      CONNECT_CONSUMER_SECURITY_PROTOCOL: 'SASL_PLAINTEXT'
      CONNECT_CONSUMER_SASL_MECHANISM: 'OAUTHBEARER'
      CONNECT_CONSUMER_SASL_LOGIN_CALLBACK_HANDLER_CLASS: 'io.confluent.kafka.clients.plugins.auth.token.TokenUserLoginCallbackHandler'
      # Default admin config
      CONNECT_ADMIN_SECURITY_PROTOCOL: 'SASL_PLAINTEXT'
      CONNECT_ADMIN_SASL_MECHANISM: 'OAUTHBEARER'
      CONNECT_ADMIN_SASL_LOGIN_CALLBACK_HANDLER_CLASS: 'io.confluent.kafka.clients.plugins.auth.token.TokenUserLoginCallbackHandler'
      # Load confluent plugins
      CONNECT_PLUGIN_PATH: "/usr/share/java,/usr/share/confluent-hub-components"
      # ============================== RBAC ========================================
      CONNECT_REST_EXTENSION_CLASSES: 'io.confluent.connect.security.ConnectSecurityExtension,io.confluent.connect.secretregistry.ConnectSecretRegistryExtension'
      CONNECT_REST_SERVLET_INITIALIZOR_CLASSES: 'io.confluent.common.security.jetty.initializer.InstallBearerOrBasicSecurityHandler'
      CONNECT_PUBLIC_KEY_PATH: '/tmp/conf/public.pem'
      CONNECT_CONFLUENT_METADATA_BOOTSTRAP_SERVER_URLS: 'http://broker:8090'
      CONNECT_CONFLUENT_METADATA_BASIC_AUTH_USER_INFO: 'fry:fry'
      CONNECT_CONFLUENT_METADATA_HTTP_AUTH_CREDENTIALS_PROVIDER: 'BASIC'
      # ========================= SECRET REGISTRY ==================================
      CONNECT_CONFIG_PROVIDERS: 'secret'
      CONNECT_CONFIG_PROVIDERS_SECRET_CLASS: 'io.confluent.connect.secretregistry.rbac.config.provider.InternalSecretConfigProvider'
      CONNECT_CONFIG_PROVIDERS_SECRET_PARAM_MASTER_ENCRYPTION_KEY: 'password1234'
      CONNECT_CONFIG_PROVIDERS_SECRET_PARAM_KAFKASTORE_TOPIC: '_secrets'
      CONNECT_CONFIG_PROVIDERS_SECRET_PARAM_KAFKASTORE_BOOTSTRAP_SERVERS: 'broker:9092'
      CONNECT_CONFIG_PROVIDERS_SECRET_PARAM_KAFKASTORE_SECURITY_PROTOCOL: 'SASL_PLAINTEXT'
      CONNECT_CONFIG_PROVIDERS_SECRET_PARAM_KAFKASTORE_SASL_MECHANISM: 'OAUTHBEARER'
      CONNECT_CONFIG_PROVIDERS_SECRET_PARAM_KAFKASTORE_SASL_LOGIN_CALLBACK_HANDLER_CLASS: 'io.confluent.kafka.clients.plugins.auth.token.TokenUserLoginCallbackHandler'
      CONNECT_CONFIG_PROVIDERS_SECRET_PARAM_KAFKASTORE_SASL_JAAS_CONFIG: |
                                                                          \
                                                                          org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required \
                                                                          username="fry" \
                                                                          password="fry" \
                                                                          metadataServerUrls="http://broker:8090";

  control-center:
    image: ${PREFIX}/cp-enterprise-control-center:${TAG}
    hostname: control-center
    container_name: control-center
    depends_on:
      zookeeper:
        condition: service_healthy
      broker:
        condition: service_healthy
      schema-registry:
        condition: service_healthy
      connect:
        condition: service_healthy
      ksql-server:
        condition: service_healthy
    ports:
      - "9021:9021"
    volumes:
      - ./conf:/tmp/conf
    healthcheck:
        test: nc -z localhost 9021
        interval: 3s
        retries: 15
        start_period: 30s
    environment:
      # CUB CLASSPATH
      CUB_CLASSPATH: '/etc/confluent/docker/docker-utils.jar:/usr/share/java/confluent-control-center/*:/usr/share/java/rest-utils/*:/usr/share/java/confluent-common/*'
      # CUB_CLASSPATH: '/etc/confluent/docker/docker-utils.jar:/usr/share/java/confluent-control-center/*'
      # general settings
      CONTROL_CENTER_BOOTSTRAP_SERVERS: 'broker:9092'
      CONTROL_CENTER_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      CONTROL_CENTER_REPLICATION_FACTOR: 1
      CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1
      CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1
      CONFLUENT_METRICS_TOPIC_REPLICATION: 1
      PORT: 9021

      # ========================= other services ==============================
      # connect
      CONTROL_CENTER_CONNECT_CONNECT1_CLUSTER: http://connect:8083

      # ksql
      CONTROL_CENTER_KSQL_KSQL1_URL: http://ksql-server:8088
      CONTROL_CENTER_KSQL_KSQL1_ADVERTISED_URL: http://localhost:8088 # access KSQL from the browser

      # schema-registry
      CONTROL_CENTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081

      # ========================= RBAC =================================
      CONTROL_CENTER_REST_AUTHENTICATION_METHOD: BEARER
      CONTROL_CENTER_AUTH_BEARER_PUBLIC_KEY_PATH: /tmp/conf/public.pem
      
      CONTROL_CENTER_METADATA_USERNAME: hermes
      CONTROL_CENTER_METADATA_PASSWORD: hermes
      CONTROL_CENTER_METADATA_URLS: http://broker:8090
      
      CONTROL_CENTER_STREAMS_SECURITY_PROTOCOL: SASL_PLAINTEXT
      # The following configs are not required by C3 itself, but are required by cub to be able to connect to kafka to check if its ready
      # Seems like C3 would generate these configs when started, but cub runs before C3 starts, so it doesn't have access to these configs
      CONTROL_CENTER_STREAMS_SASL_MECHANISM: OAUTHBEARER
      CONTROL_CENTER_STREAMS_SASL_LOGIN_CALLBACK_HANDLER_CLASS: io.confluent.kafka.clients.plugins.auth.token.TokenUserLoginCallbackHandler
      CONTROL_CENTER_STREAMS_SASL_JAAS_CONFIG: |
                                                \
                                                org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required \
                                                username="hermes" \
                                                password="hermes" \
                                                metadataServerUrls="http://broker:8090";
