.. _ccloud-cli-tutorial:

Tutorial: |ccloud| CLI
=======================

Overview
--------

This tutorial shows you how to use the `Confluent Cloud CLI
<https://docs.confluent.io/current/cloud/cli/install.html>`__ to interact with
your `Confluent Cloud <https://confluent.cloud/login>`__ cluster.
Following the workflow in this tutorial, you accomplish the following steps:

-  `Create a new Confluent Cloud environment`_
-  `Create a new Confluent Cloud cluster`_
-  `Create a new API key/secret pair for user`_
-  `Produce and consume records with Confluent Cloud CLI`_
-  `Create a new service account with an API key/secret pair`_
-  `Run a Java producer without ACLs`_
-  `Run a Java producer with ACLs`_
-  `Run a Java producer with a prefixed ACL`_
-  `Run kafka-connect-datagen connector with wildcard ACLs`_
-  `Run a Java consumer with a Wildcard ACL`_
-  `Clean up your Confluent Cloud resources`_


Prerequisites
~~~~~~~~~~~~~~

-  Access to `Confluent Cloud <https://confluent.cloud/login>`__. Note that this
   tutorial uses real resources in |ccloud|, and it creates and deletes
   topics, service accounts, API keys, and ACLs.

-  |ccloud| user credentials saved in ``~/.netrc``. (Use ``ccloud login --save``
   when logging in to the |ccloud| CLI. The ``--save`` flag will save your login
   credentials to the ``~/.netrc`` file.)

-  Local `install of Confluent Cloud CLI
   <https://docs.confluent.io/current/cloud/cli/install.html>`__ (v1.7.0 or later)

-  `Docker <https://docs.docker.com/get-docker/>`__ and `Docker Compose
   <https://docs.docker.com/compose/install/>`__ for the local |kconnect| worker

-  .. include:: ../../ccloud/docs/includes/prereq_timeout.rst

-  `mvn <https://maven.apache.org/install.html>`__ installed on your host

-  `jq <https://github.com/stedolan/jq/wiki/Installation>`__ installed on your host


Confluent Cloud Promo Code
~~~~~~~~~~~~~~~~~~~~~~~~~~

The first 20 users to sign up for `Confluent Cloud
<https://www.confluent.io/confluent-cloud/?utm_source=github&utm_medium=demo&utm_campaign=ch.examples_type.community_content.beginner-cloud>`__
and use promo code ``C50INTEG`` will receive an additional $50 free usage
(`details
<https://www.confluent.io/confluent-cloud-promo-disclaimer/?utm_source=github&utm_medium=demo&utm_campaign=ch.examples_type.community_content.beginner-cloud>`__).


Run the tutorial
----------------

To run this tutorial, complete the following steps:

#. Clone the Confluent examples repository.

   .. code-block:: bash

       git clone https://github.com/confluentinc/examples.git

#. Navigate to the ``examples/ccloud/beginner-cloud/`` directory and switch to the |cp| release branch:

   .. codewithvars:: bash

       cd examples/ccloud/beginner-cloud/
       git checkout |release_post_branch|

#. If you want to manually step through the tutorial, which is advised for new users who want to gain familiarity with |ccloud| CLI, skip ahead to the next section. Alternatively, you can run the full tutorial end-to-end with the :devx-examples:`start.sh script|ccloud/beginner-cloud/start.sh`, which automates all the steps in the tutorial:

   .. code-block:: bash

         ./start.sh


Create a new Confluent Cloud environment
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

#. Run the following command to create a new |ccloud| environment
   ``demo-script-env``:

   .. code-block:: bash

      ccloud environment create demo-script-env -o json

#. Your output should resemble below. The value of the environment ID may differ in your output, in this case ``env-5qz2q``.

   .. code-block:: text

      {
        "id": "env-5qz2q",
        "name": "demo-script-env"
      }

   .. note::

      The values for certain variables, including your environment ID,
      |ak| cluster ID, API key, will be unique and may not match the output
      exactly.

#. Specify ``env-5qz2q`` as the active environment by running the following
   command:

   .. code-block:: bash

       ccloud environment use env-5qz2q

#. Verify your output resembles:

   .. code-block:: text

      Now using "env-5qz2q" as the default (active) environment.


Create a new Confluent Cloud cluster
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

#. Run the following command to create a new |ccloud| cluster
   ``demo-kafka-cluster``. It may take up to 5 minutes for the |ak| cluster to be
   ready.

   .. code-block:: bash

      ccloud kafka cluster create demo-kafka-cluster --cloud aws --region us-west-2

   .. tip::

      You may choose any provider or region from the list generated by running
      ``ccloud kafka region list1``.

#. Your output should resemble below. The value of the |ak| cluster ID may differ in your output, in this case ``lkc-x6m01``, and the value of the |ak| cluster endpoint may differ in your output, in this case ``pkc-4kgmg.us-west-2.aws.confluent.cloud:9092``.

   .. code-block:: text

      +--------------+---------------------------------------------------------+
      | Id           | lkc-x6m01                                               |
      | Name         | demo-kafka-cluster                                      |
      | Type         | BASIC                                                   |
      | Ingress      |                                                     100 |
      | Egress       |                                                     100 |
      | Storage      |                                                    5000 |
      | Provider     | aws                                                     |
      | Availability | LOW                                                     |
      | Region       | us-west-2                                               |
      | Status       | UP                                                      |
      | Endpoint     | SASL_SSL://pkc-4kgmg.us-west-2.aws.confluent.cloud:9092 |
      | ApiEndpoint  | https://pkac-ldgj1.us-west-2.aws.confluent.cloud        |
      +--------------+---------------------------------------------------------+

#. Specify ``lkc-x6m01`` as the active |ak| cluster by running the following
   command:

   .. code-block:: bash

      ccloud kafka cluster use lkc-x6m01

#. Verify your output resembles:

   .. code-block:: text

       Set Kafka cluster "lkc-x6m01" as the active cluster for environment "env-5qz2".


Create a new API key/secret pair for user
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

#. Run the following command to create a user API key/secret pair for your |ak| cluster ``lkc-x6m01``.

   .. code-block:: bash

      cloud api-key create --description "Demo credentials" --resource lkc-x6m01 -o json

#. Your output should resemble below. The value of the API key may differ in your output, in this case ``QX7X4VA4DFJTTOIA``.

   .. code-block:: text

      {
         "key": "QX7X4VA4DFJTTOIA",
         "secret": "fjcDDyr0Nm84zZr77ku/AQqCKQOOmb35Ql68HQnb60VuU+xLKiu/n2UNQ0WYXp/D"
      }

#. Specify that you want to use the API key ``QX7X4VA4DFJTTOIA`` for the |ak| cluster ``lkc-x6m01``:

   .. code-block:: bash

      ccloud api-key use QX7X4VA4DFJTTOIA --resource lkc-x6m01

   Your output should resemble:

   .. code-block:: text

      Set the API Key "QX7X4VA4DFJTTOIA" as the active API key for ``lkc-x6m0``.

      Waiting for Confluent Cloud cluster to be ready and for credentials to propagate
      ....

Produce and consume records with Confluent Cloud CLI
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

#. Run the following command to create a new |ak| topic ``demo-topic-1``:

   .. code-block:: bash

      ccloud kafka topic create demo-topic-1

#. Produce 10 messages to topic ``demo-topic-1`` by running the following
   commands:

   .. code-block:: bash

         (for i in `seq 1 10`; do echo "${i}" ; done) | \
           ccloud kafka topic produce demo-topic-1

#. Verify your output resembles:

   .. code-block:: text

      Starting Kafka Producer. ^C or ^D to exit
      1
      2
      3
      4
      5
      6
      7
      8
      9
      10

#. Run the following command to consume messages from topic ``demo-topic-1``. The flag ``-b`` allows the consumer to read from the beginning of the topic.

   .. code-block:: bash

      ccloud kafka topic consume demo-topic-1 -b

#. Verify your output resembles:

   .. code-block:: text

      Starting Kafka Consumer. ^C or ^D to exit
      2
      3
      9
      4
      5
      7
      10
      1
      6
      8

#. Press ``CTRL-C`` to stop the consumer.


Create a new service account with an API key/secret pair
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

#. Run the following commmand to create a new service account:

   .. code-block:: bash

      ccloud service-account create demo-app-3288 --description demo-app-3288 -o json

#. Your output should resemble below. The value of the service account ID may differ in your output, in this case ``104349``.

   .. code-block:: text

      {
         "id": 104349,
         "name": "demo-app-3288",
         "description": "demo-app-3288"
      }

#. Create an API key and secret for the service account ``104349`` for the |ak| cluster ``lkc-x6m01``
   by running the following command:

   .. code-block:: bash

      ccloud api-key create --service-account 104349 --resource lkc-x6m01 -o json

#. Your output should resemble below. The value of the API key for the service account may differ in your output, in this case ``ESN5FSNDHOFFSUEV``.

   .. code-block:: text

      {
        "key": "ESN5FSNDHOFFSUEV",
        "secret": "nzBEyC1k7zfLvVON3vhBMQrNRjJR7pdMc2WLVyyPscBhYHkMwP6VpPVDTqhctamB"
      }

#. Create a local configuration file ``/tmp/client.config`` with |ccloud|
   connection information using the newly created |ak| cluster and the
   API key and secret for the service account:

   .. code-block:: text

       ssl.endpoint.identification.algorithm=https
       sasl.mechanism=PLAIN
       security.protocol=SASL_SSL
       bootstrap.servers=pkc-4kgmg.us-west-2.aws.confluent.cloud:9092
       sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username\="ESN5FSNDHOFFSUEV" password\="nzBEyC1k7zfLvVON3vhBMQrNRjJR7pdMc2WLVyyPscBhYHkMwP6VpPVDTqhctamB";

#. Wait about 90 seconds for the |ccloud| cluster to be ready and for the
   service account credentials to propagate.


Run a Java producer without ACLs
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

#. By default, no ACLs are configured for the service account, which means the
   service account has no access to any |ccloud| resources. Run the following command
   to verify no ACLs are configured:

   .. code-block:: bash

      ccloud kafka acl list --service-account 104349

   Your output should resemble:

   .. code-block:: text

        ServiceAccountId | Permission | Operation | Resource | Name | Type
      +------------------+------------+-----------+----------+------+------+

#. Run a Java producer to ``demo-topic-1`` before configuring ACLs (expected
   to fail). Note that you pass in an argument to ``/tmp/client.config`` which
   has the |ccloud| connection information:

   .. code-block:: bash

      mvn -q -f ../../clients/cloud/java/pom.xml exec:java -Dexec.mainClass="io.confluent.examples.clients.cloud.ProducerExample" -Dexec.args="/tmp/client.config demo-topic-1" -Dlog4j.configuration=file:log4j.properties > /tmp/log.1 2>&1

#. Verify you see ``org.apache.kafka.common.errors.TopicAuthorizationException``
   in the log file ``/tmp/log.1`` as shown in the following example (expected
   because there are no ACLs to allow this client application):

   .. code-block:: text

       [ERROR] Failed to execute goal org.codehaus.mojo:exec-maven-plugin:1.2.1:java (default-cli) on project clients-example: An exception occured while executing the Java class. null: InvocationTargetException: java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.TopicAuthorizationException: Authorization failed. -> [Help 1]

Run a Java producer with ACLs
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

#. Run the following commands to create ACLs for the service account:

   .. code-block:: bash

      ccloud kafka acl create --allow --service-account 104349 --operation CREATE --topic demo-topic-1
      ccloud kafka acl create --allow --service-account 104349 --operation WRITE --topic demo-topic-1

#. Verify your output resembles:

   .. code-block:: text

         ServiceAccountId | Permission | Operation | Resource |     Name     |  Type
       +------------------+------------+-----------+----------+--------------+---------+
         User:104349      | ALLOW      | CREATE    | TOPIC    | demo-topic-1 | LITERAL

         ServiceAccountId | Permission | Operation | Resource |     Name     |  Type
       +------------------+------------+-----------+----------+--------------+---------+
         User:104349      | ALLOW      | WRITE     | TOPIC    | demo-topic-1 | LITERAL

#. Run the following command and verify the ACLs were configured:

   .. code-block:: bash

      ccloud kafka acl list --service-account 104349

   Your output should resemble below. Observe that the ACL Type is ``LITERAL``.

   .. code-block:: text

         ServiceAccountId | Permission | Operation | Resource |     Name     |  Type
       +------------------+------------+-----------+----------+--------------+---------+
         User:104349      | ALLOW      | CREATE    | TOPIC    | demo-topic-1 | LITERAL
         User:104349      | ALLOW      | WRITE     | TOPIC    | demo-topic-1 | LITERAL

#. Run the Java producer to ``demo-topic-1`` after configuring the ACLs (expected to pass):

   .. code-block:: bash

      mvn -q -f ../../clients/cloud/java/pom.xml exec:java -Dexec.mainClass="io.confluent.examples.clients.cloud.ProducerExample" -Dexec.args="/tmp/client.config demo-topic-1" -Dlog4j.configuration=file:log4j.properties > /tmp/log.2 2>&1

#. Verify you see the ``10 messages were produced to topic`` message in the
   log file ``/tmp/log.2`` as shown in the following example:

   .. code-block:: text

         [2020-08-29 13:52:10,836] WARN The configuration 'sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
         [2020-08-29 13:52:10,837] WARN The configuration 'ssl.endpoint.identification.algorithm' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
         Producing record: alice	{"count":0}
         Producing record: alice	{"count":1}
         Producing record: alice	{"count":2}
         Producing record: alice	{"count":3}
         Producing record: alice	{"count":4}
         Producing record: alice	{"count":5}
         Producing record: alice	{"count":6}
         Producing record: alice	{"count":7}
         Producing record: alice	{"count":8}
         Producing record: alice	{"count":9}
         Produced record to topic demo-topic-1 partition [3] @ offset 0
         Produced record to topic demo-topic-1 partition [3] @ offset 1
         Produced record to topic demo-topic-1 partition [3] @ offset 2
         Produced record to topic demo-topic-1 partition [3] @ offset 3
         Produced record to topic demo-topic-1 partition [3] @ offset 4
         Produced record to topic demo-topic-1 partition [3] @ offset 5
         Produced record to topic demo-topic-1 partition [3] @ offset 6
         Produced record to topic demo-topic-1 partition [3] @ offset 7
         Produced record to topic demo-topic-1 partition [3] @ offset 8
         Produced record to topic demo-topic-1 partition [3] @ offset 9
         10 messages were produced to topic demo-topic-1

#. Delete the ACLs:

   .. code-block:: bash

      ccloud kafka acl delete --allow --service-account 104349 --operation CREATE --topic demo-topic-1
      ccloud kafka acl delete --allow --service-account 104349 --operation WRITE --topic demo-topic-1

   Verify you see two ``Deleted ACLs.`` messages.


Run a Java producer with a prefixed ACL
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

#. Create a new |ak| topic ``demo-topic-2``:

   .. code-block:: bash

      ccloud kafka topic create demo-topic-2

   Verify you see the ``Created topic "demo-topic-2"`` message.

#. Run the following command to create ACLs for the producer using a prefixed ACL
   which matches any topic that starts with the prefix ``demo-topic``:

   .. code-block:: bash

      ccloud kafka acl create --allow --service-account 104349 --operation CREATE --topic demo-topic --prefix
      ccloud kafka acl create --allow --service-account 104349 --operation WRITE --topic demo-topic --prefix

#. Verify your output resembles:

   .. code-block:: text

      ServiceAccountId | Permission | Operation | Resource |    Name    |   Type
      +------------------+------------+-----------+----------+------------+----------+
      User:104349      | ALLOW      | CREATE    | TOPIC    | demo-topic | PREFIXED

      ServiceAccountId | Permission | Operation | Resource |    Name    |   Type
      +------------------+------------+-----------+----------+------------+----------+
      User:104349      | ALLOW      | WRITE     | TOPIC    | demo-topic | PREFIXED

#. Verify the ACLs were configured by running the following command:

   .. code-block:: bash

      ccloud kafka acl list --service-account 104349

   Your output should resemble below. Observe that the ACL Type is ``PREFIXED``.

   .. code-block:: text

         ServiceAccountId | Permission | Operation | Resource |    Name    |   Type
       +------------------+------------+-----------+----------+------------+----------+
         User:104349      | ALLOW      | WRITE     | TOPIC    | demo-topic | PREFIXED
         User:104349      | ALLOW      | CREATE    | TOPIC    | demo-topic | PREFIXED

#. Run the Java producer to ``demo-topic-2``, which should match the newly
   created prefixed ACLs.

   .. code-block:: bash

      mvn -q -f ../../clients/cloud/java/pom.xml exec:java -Dexec.mainClass="io.confluent.examples.clients.cloud.ProducerExample" -Dexec.args="/tmp/client.config demo-topic-2" -Dlog4j.configuration=file:log4j.properties > /tmp/log.3 2>&1

#. Verify you see the ``10 messages were produced to topic`` message in the log
   file ``/tmp/log.3`` as shown in the following example:

   .. code-block:: text

      [2020-08-29 13:52:39,012] WARN The configuration 'sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
      [2020-08-29 13:52:39,013] WARN The configuration 'ssl.endpoint.identification.algorithm' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
      Producing record: alice	{"count":0}
      Producing record: alice	{"count":1}
      Producing record: alice	{"count":2}
      Producing record: alice	{"count":3}
      Producing record: alice	{"count":4}
      Producing record: alice	{"count":5}
      Producing record: alice	{"count":6}
      Producing record: alice	{"count":7}
      Producing record: alice	{"count":8}
      Producing record: alice	{"count":9}
      Produced record to topic demo-topic-2 partition [3] @ offset 0
      Produced record to topic demo-topic-2 partition [3] @ offset 1
      Produced record to topic demo-topic-2 partition [3] @ offset 2
      Produced record to topic demo-topic-2 partition [3] @ offset 3
      Produced record to topic demo-topic-2 partition [3] @ offset 4
      Produced record to topic demo-topic-2 partition [3] @ offset 5
      Produced record to topic demo-topic-2 partition [3] @ offset 6
      Produced record to topic demo-topic-2 partition [3] @ offset 7
      Produced record to topic demo-topic-2 partition [3] @ offset 8
      Produced record to topic demo-topic-2 partition [3] @ offset 9
      10 messages were produced to topic demo-topic-2

#. Run the following commands to delete ACLs:

   .. code-block:: bash

      ccloud kafka acl delete --allow --service-account 104349 --operation CREATE --topic demo-topic --prefix
      ccloud kafka acl delete --allow --service-account 104349 --operation WRITE --topic demo-topic --prefix

   You should see two ``Deleted ACLs.`` messages.


Run kafka-connect-datagen connector with wildcard ACLs
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

#. Create a new |ak| topic ``demo-topic-3``:

   .. code-block:: bash

      ccloud kafka topic create demo-topic-3

   You should see a ``Created topic "demo-topic-3"`` message.

#. Run the following command to create an ACL that allows creation of any topic:

   .. code-block:: bash

      ccloud kafka acl create --allow --service-account 104349 --operation CREATE --topic '*'

#. Verify your output reesmbles:

   .. code-block:: text

         ServiceAccountId | Permission | Operation | Resource | Name |  Type
       +------------------+------------+-----------+----------+------+---------+
         User:104349      | ALLOW      | CREATE    | TOPIC    | *    | LITERAL


#. Run the following command to allow service account ID ``104349`` to write to
   any topic.

   .. code-block:: bash

      ccloud kafka acl create --allow --service-account 104349 --operation WRITE --topic '*'

#. Verify your output reesmbles:

   .. code-block:: text

         ServiceAccountId | Permission | Operation | Resource | Name |  Type
       +------------------+------------+-----------+----------+------+---------+
         User:104349      | ALLOW      | WRITE     | TOPIC    | *    | LITERAL


#. Run the following command to allow user ``104349`` to read from
   any topic.

   .. code-block:: bash

      ccloud kafka acl create --allow --service-account 104349 --operation READ --topic '*'

#. Verify your output resembles:

   .. code-block:: text

         ServiceAccountId | Permission | Operation | Resource | Name |  Type
       +------------------+------------+-----------+----------+------+---------+
         User:104349      | ALLOW      | READ      | TOPIC    | *    | LITERAL

#. Run the following command to allow user ``104349`` to have a consumer group
   called ``connect``.

   .. code-block:: bash

       ccloud kafka acl create --allow --service-account 104349 --operation READ --consumer-group connect

   Your output should resemble:

   .. code-block:: text

         ServiceAccountId | Permission | Operation | Resource |  Name   |  Type
         +------------------+------------+-----------+----------+---------+---------+
         User:104349      | ALLOW      | READ      | GROUP    | connect | LITERAL

#. Verify the ACLs were configured by running the following command:

   .. code-block:: bash

      ccloud kafka acl list --service-account 104349

   Your output should resemble:

   .. code-block:: text

         ServiceAccountId | Permission | Operation | Resource |  Name   |  Type
       +------------------+------------+-----------+----------+---------+---------+
         User:104349      | ALLOW      | WRITE     | TOPIC    | *       | LITERAL
         User:104349      | ALLOW      | CREATE    | TOPIC    | *       | LITERAL
         User:104349      | ALLOW      | READ      | TOPIC    | *       | LITERAL
         User:104349      | ALLOW      | READ      | GROUP    | connect | LITERAL

#. Generate environment variables with |ccloud| connection information for
   |kconnect| to use:

   .. code-block:: text

      ../../ccloud/ccloud-generate-cp-configs.sh /tmp/client.config &>/dev/null
      source delta_configs/env.delta

#. Run the following :devx-examples:`docker-compose.yml file|ccloud/beginner-cloud/docker-compose.yml`
   which is a |kconnect| container with the`kafka-connect-datagen <https://www.confluent.io/hub/confluentinc/kafka-connect-datagen>`__ plugin:

   .. code-block:: bash

      docker-compose up -d

   Your output should resemble:

   .. code-block:: text

      Creating connect-cloud ... done
      Waiting up to 180 seconds for Docker container for connect to be up
      ............

#. Post the configuration for the kafka-connect-datagen connector that produces
   pageviews data to |ccloud| topic ``demo-topic-3``:

   .. code-block:: text

         DATA=$( cat << EOF
         {
            "name": "datagen-demo-topic-3",
            "config": {
              "connector.class": "io.confluent.kafka.connect.datagen.DatagenConnector",
              "kafka.topic": "demo-topic-3",
              "quickstart": "pageviews",
              "key.converter": "org.apache.kafka.connect.storage.StringConverter",
              "value.converter": "org.apache.kafka.connect.json.JsonConverter",
              "value.converter.schemas.enable": "false",
              "max.interval": 5000,
              "iterations": 1000,
              "tasks.max": "1"
            }
         }
         EOF
         )

         curl --silent --output /dev/null -X POST -H "Content-Type: application/json" --data "${DATA}" http://localhost:8083/connectors


#. Wait about 20 seconds for kafka-connect-datagen to start producing messages.

#. Run the following command to verify connector is running:

   .. code-block:: bash

      curl --silent http://localhost:8083/connectors/datagen-demo-topic-3/status | jq -r '.'

   Your output should resemble:

   .. code-block:: text

      {
         "name": "datagen-demo-topic-3",
         "connector": {
           "state": "RUNNING",
           "worker_id": "connect:8083"
         },
         "tasks": [
           {
             "id": 0,
             "state": "RUNNING",
             "worker_id": "connect:8083"
           }
         ],
         "type": "source"
      }


Run a Java consumer with a Wildcard ACL
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

#. Create ACLs for the consumer using a wildcard by running the following
   commands:

   .. code-block:: bash

      ccloud kafka acl create --allow --service-account 104349 --operation READ --consumer-group demo-beginner-cloud-1
      ccloud kafka acl create --allow --service-account 104349 --operation READ --topic '*'

#. Verify your output resembles:

   .. code-block:: text

        ServiceAccountId | Permission | Operation | Resource |         Name          |  Type
      +------------------+------------+-----------+----------+-----------------------+---------+
        User:104349      | ALLOW      | READ      | GROUP    | demo-beginner-cloud-1 | LITERAL

        ServiceAccountId | Permission | Operation | Resource | Name |  Type
      +------------------+------------+-----------+----------+------+---------+
        User:104349      | ALLOW      | READ      | TOPIC    | *    | LITERAL


#. Verify the ACLs were configured by running the following command:

   .. code-block:: bash

      ccloud kafka acl list --service-account 104349

   Your output should resemble:

   .. code-block:: text

         ServiceAccountId | Permission | Operation | Resource |         Name          |  Type
       +------------------+------------+-----------+----------+-----------------------+---------+
         User:104349      | ALLOW      | READ      | GROUP    | connect               | LITERAL
         User:104349      | ALLOW      | CREATE    | TOPIC    | *                     | LITERAL
         User:104349      | ALLOW      | WRITE     | TOPIC    | *                     | LITERAL
         User:104349      | ALLOW      | READ      | TOPIC    | *                     | LITERAL
         User:104349      | ALLOW      | READ      | GROUP    | demo-beginner-cloud-1 | LITERAL


#. Run the Java consumer from ``demo-topic-3`` which is populated by kafka-connect-datagen.

   .. code-block:: bash

      mvn -q -f ../../clients/cloud/java/pom.xml exec:java -Dexec.mainClass="io.confluent.examples.clients.cloud.ConsumerExamplePageviews" -Dexec.args="/tmp/client.config demo-topic-3" -Dlog4j.configuration=file:log4j.properties > /tmp/log.4 2>&1

#. Verify you see the ``Consumed record with`` message in the log file
   ``/tmp/log.4`` as shown in the following example:

   .. code-block:: text

      Consumed record with key 1 and value {"viewtime":1,"userid":"User_6","pageid":"Page_82"}
      Consumed record with key 71 and value {"viewtime":71,"userid":"User_6","pageid":"Page_11"}
      Consumed record with key 51 and value {"viewtime":51,"userid":"User_7","pageid":"Page_24"}
      Consumed record with key 31 and value {"viewtime":31,"userid":"User_7","pageid":"Page_68"}
      Consumed record with key 81 and value {"viewtime":81,"userid":"User_5","pageid":"Page_25"}
      Consumed record with key 41 and value {"viewtime":41,"userid":"User_2","pageid":"Page_88"}
      Consumed record with key 91 and value {"viewtime":91,"userid":"User_2","pageid":"Page_74"}

#. Delete the ACLs by running the following command:

   .. code-block:: bash

      ccloud kafka acl delete --allow --service-account 104349 --operation READ --consumer-group demo-beginner-cloud-1
      ccloud kafka acl delete --allow --service-account 104349 --operation READ --topic '*'

   You should see two ``Deleted ACLs.`` messages.

#. Stop Docker:

   .. code-block:: bash

        docker-compose down

#. Verify you see the following output:

   .. code-block:: text

      Stopping connect-cloud ... done
      Removing connect-cloud ... done
      Removing network beginner-cloud_default

#. Delete the ACLs:

   .. code-block:: bash

      ccloud kafka acl delete --allow --service-account 104349 --operation CREATE --topic '*'
      ccloud kafka acl delete --allow --service-account 104349 --operation WRITE --topic '*'
      ccloud kafka acl delete --allow --service-account 104349 --operation READ --topic '*'
      ccloud kafka acl delete --allow --service-account 104349 --operation READ --consumer-group connect

   You should see a ``Deleted ACLs.`` message after running each of the previous commands.


Clean up your Confluent Cloud resources
---------------------------------------

#. Run the following command to delete the service account:

   .. code-block:: bash

      ccloud service-account delete 104349

#. Complete the following steps to delete all the |ak| topics:

   a. Delete ``demo-topic-1``:

      .. code-block:: bash

         ccloud kafka topic delete demo-topic-1

      You should see: ``Deleted topic "demo-topic-1"``.

   b. Delete ``demo-topic-2``:

      .. code-block:: bash

         ccloud kafka topic delete demo-topic-2

      You should see: ``Deleted topic "demo-topic-2"``.

   c. Delete ``demo-topic-3``:

      .. code-block:: bash

         ccloud kafka topic delete demo-topic-3

      You should see: ``Deleted topic "demo-topic-3"``.

   d. Delete ``connect-configs``, one of the 3 topics created by the |kconnect| worker:

      .. code-block:: bash

         ccloud kafka topic delete connect-configs

      You should see: ``Deleted topic "connect-configs"``.

   e. Delete ``connect-offsets``, one of the 3 topics created by the |kconnect| worker:

      .. code-block:: bash

         ccloud kafka topic delete connect-offsets

      You should see: ``Deleted topic "connect-offsets"``.

   f. Delete ``connect-status``, one of the 3 topics created by the |kconnect| worker:

      .. code-block:: bash

         ccloud kafka topic delete connect-status

      You should see: ``Deleted topic "connect-status"``.

#. Run the following commands to delete the API keys:

   .. code-block:: bash

      ccloud api-key delete ESN5FSNDHOFFSUEV
      ccloud api-key delete QX7X4VA4DFJTTOIA

#. Delete the |ak| cluster:

   .. code-block:: bash

      ccloud kafka cluster delete lkc-x6m01

#. Delete the environment:

   .. code-block:: bash

      ccloud environment delete env-5qz2q

   You should see: ``Deleted environment "env-5qz2q"``.

If you run a demo that ends prematurely, you may receive the following error
message when trying to run the demo again (``ccloud environment create
demo-script-env``):

.. code-block:: text

      Error: 1 error occurred:
         * error creating account: Account name is already in use

      Failed to create environment demo-script-env. Please troubleshoot and run again

In this case, run the following script to delete the demoâ€™s topics, |ak| cluster, and environment.

.. code-block:: bash

   ./cleanup.sh


Advanced usage
--------------

The demo script provides variables that allow you to alter the default |ak|
cluster name, cloud provider, and region. For example:

.. code-block:: bash

   CLUSTER_NAME=my-demo-cluster CLUSTER_CLOUD=aws CLUSTER_REGION=us-west-2 ./start.sh

Here are the variables and their default values:

.. list-table::
   :widths: 50 50
   :header-rows: 1

   * - Variable
     - Default
   * - ``CLUSTER_NAME``
     - demo-kafka-cluster
   * - ``CLUSTER_CLOUD``
     - aws
   * - ``CLUSTER_REGION``
     - us-west-2


Additional Resources
---------------------

-  See the `Best Practices for Developing Kafka Applications on
   Confluent Cloud
   <https://assets.confluent.io/m/14397e757459a58d/original/20200205-WP-Best_Practices_for_Developing_Apache_Kafka_Applications_on_Confluent_Cloud.pdf?utm_source=github&utm_medium=demo&utm_campaign=ch.examples_type.community_content.ccloud>`__
   whitepaper for a guide to configuring, monitoring, and optimizing
   your |ak| client applications when using |ccloud|.

- See other :ref:`ccloud-demos-overview`.
